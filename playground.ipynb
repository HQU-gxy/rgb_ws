{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deploy.preprocess import decode_image\n",
    "from deploy.infer import Detector, DetectorPicoDet, PredictConfig, print_arguments, get_test_images, bench_log\n",
    "from deploy.keypoint_infer import KeyPointDetector, PredictConfig_KeyPoint\n",
    "from deploy.visualize import visualize_pose\n",
    "from deploy.benchmark_utils import PaddleInferBenchmark\n",
    "from deploy.utils import get_current_memory_mb\n",
    "from deploy.keypoint_postprocess import translate_to_ori_images\n",
    "from pathlib import Path\n",
    "from typing import Literal, List, Dict, TypedDict, Any, cast\n",
    "from pydantic import BaseModel\n",
    "from numpy.typing import NDArray\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "from cv2.typing import MatLike\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "class DetectionResult(TypedDict):\n",
    "    # images\n",
    "    # box count\n",
    "    boxes_num: NDArray[np.integer]\n",
    "    # images\n",
    "    # bounding box\n",
    "    #  - x y w h (?) or x1 y1 x2 y2\n",
    "    boxes:NDArray[np.floating]\n",
    "\n",
    "class KeyPointDetectionResult(TypedDict):\n",
    "    # images\n",
    "    # key points\n",
    "    # x y possibility (?)\n",
    "    keypoint: NDArray[np.floating]\n",
    "    # images\n",
    "    # bounding boxes\n",
    "    #  - x y w h (?) or x1 y1 x2 y2\n",
    "    bboxes: NDArray[np.integer]\n",
    "\n",
    "class ImageInfo(TypedDict):\n",
    "    # im.shape[:2]\n",
    "    shape: NDArray[np.float32]\n",
    "    # scale_factor\n",
    "    scale_factor: NDArray[np.float32]\n",
    "\n",
    "DeviceType = Literal[\"GPU\", \"CPU\", \"XPU\"]\n",
    "# paddle/trt_fp32/trt_fp16/trt_int8\n",
    "RunMode = Literal[\"paddle\", \"trt_fp32\", \"trt_fp16\", \"trt_int8\"]\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "DETECTION_MODEL_DIR = MODELS_DIR / \"picodet_v2_s_320_pedestrian\"\n",
    "KEYPOINT_MODEL_DIR = MODELS_DIR / \"tinypose_256x192\"\n",
    "DEVICE: DeviceType = \"GPU\"\n",
    "RUN_MODE:RunMode = \"paddle\"\n",
    "USE_DARK_POSE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionParams(BaseModel):\n",
    "    detection_thres:float\n",
    "    key_points_visual_thresh:float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_given_det(\n",
    "        image: MatLike,\n",
    "        det_res: DetectionResult,\n",
    "        keypoint_detector: KeyPointDetector,\n",
    "        run_benchmark: bool = False) -> KeyPointDetectionResult:\n",
    "    keypoint_res = {}\n",
    "\n",
    "    rec_images, records, det_rects = keypoint_detector.get_person_from_rect(\n",
    "        image, det_res)\n",
    "\n",
    "    if len(det_rects) == 0:\n",
    "        keypoint_res['keypoint'] = [[], []]\n",
    "        return keypoint_res\n",
    "\n",
    "    keypoint_vector = []\n",
    "    score_vector = []\n",
    "\n",
    "    rect_vector = det_rects\n",
    "    keypoint_results = keypoint_detector.predict_image(rec_images,\n",
    "                                                       run_benchmark,\n",
    "                                                       repeats=10,\n",
    "                                                       visual=False)\n",
    "    keypoint_vector, score_vector = translate_to_ori_images(\n",
    "        keypoint_results, np.array(records))\n",
    "    keypoint_res['keypoint'] = [\n",
    "        keypoint_vector.tolist(),\n",
    "        score_vector.tolist()\n",
    "    ] if len(keypoint_vector) > 0 else [[], []]\n",
    "    keypoint_res['bbox'] = rect_vector\n",
    "    return keypoint_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the arch is not PicoDet\n",
    "detector = Detector(DETECTION_MODEL_DIR, device=DEVICE, run_mode=RUN_MODE)\n",
    "kp_detector = KeyPointDetector(KEYPOINT_MODEL_DIR,\n",
    "                               device=DEVICE,\n",
    "                               run_mode=RUN_MODE,\n",
    "                               use_dark=USE_DARK_POSE)\n",
    "\n",
    "\n",
    "# detector needs RGB with dtype uint8 (8UC3)\n",
    "def preprocess(frame: MatLike) -> tuple[MatLike, ImageInfo]:\n",
    "    assert frame.dtype == np.uint8, \"Image pixel type should be uint8_t\"\n",
    "    assert frame.shape[2] == 3, \"The image does not have 3 channels\"\n",
    "    im = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    info: ImageInfo = {\n",
    "        \"shape\": np.array(im.shape[:2], dtype=np.float32),\n",
    "        \"scale_factor\": np.array([1., 1.], dtype=np.float32)\n",
    "    }\n",
    "    return im, info\n",
    "\n",
    "\n",
    "def predict(image: MatLike, detector: Detector,\n",
    "            topdown_kp_detector: KeyPointDetector, params: DetectionParams):\n",
    "    detections = detector.predict_image([image], visual=False)\n",
    "    det_res = detector.filter_box(detections, params.detection_thres)\n",
    "    det_res = cast(DetectionResult, det_res)\n",
    "    kp_res = predict_with_given_det(image, det_res, topdown_kp_detector, 1)\n",
    "    kp_res = cast(KeyPointDetectionResult, kp_res)\n",
    "    return det_res, kp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"test.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, info = preprocess(img)\n",
    "plt.imshow(rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = DetectionParams(detection_thres=0.5, key_points_visual_thresh=0.5)\n",
    "det, kp = predict(rgb, detector, kp_detector, params)\n",
    "display(det)\n",
    "display(kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(\n",
    "    frame: MatLike,\n",
    "    results: KeyPointDetectionResult,\n",
    "    visual_thresh: float = 0.6,\n",
    "    bb_thickness:int = 1,\n",
    "    kp_stick_width:int = 2,\n",
    "):\n",
    "    import math\n",
    "    skeletons, scores = results['keypoint']\n",
    "    skeletons = np.array(skeletons)\n",
    "    kpt_nums = 17\n",
    "    if len(skeletons) > 0:\n",
    "        kpt_nums = skeletons.shape[1]\n",
    "    if kpt_nums == 17:  #plot coco keypoint\n",
    "        EDGES = [(0, 1), (0, 2), (1, 3), (2, 4), (3, 5), (4, 6), (5, 7),\n",
    "                 (6, 8), (7, 9), (8, 10), (5, 11), (6, 12), (11, 13), (12, 14),\n",
    "                 (13, 15), (14, 16), (11, 12)]\n",
    "    else:  #plot mpii keypoint\n",
    "        EDGES = [(0, 1), (1, 2), (3, 4), (4, 5), (2, 6),\n",
    "                 (3, 6), (6, 7), (7, 8), (8, 9), (10, 11), (11, 12), (13, 14),\n",
    "                 (14, 15), (8, 12), (8, 13)]\n",
    "    NUM_EDGES = len(EDGES)\n",
    "\n",
    "    colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "            [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "            [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "    cmap = matplotlib.colormaps.get_cmap('hsv')\n",
    "    plt.figure()\n",
    "\n",
    "    img = cv2.imread(frame) if type(frame) == str else frame\n",
    "\n",
    "    color_set = results['colors'] if 'colors' in results else None\n",
    "\n",
    "    if 'bbox' in results:\n",
    "        bboxs = results['bbox']\n",
    "        for j, rect in enumerate(bboxs):\n",
    "            xmin, ymin, xmax, ymax = rect\n",
    "            color = colors[0] if color_set is None else colors[color_set[j] %\n",
    "                                                               len(colors)]\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, bb_thickness)\n",
    "\n",
    "    canvas = img.copy()\n",
    "    for i in range(kpt_nums):\n",
    "        for j in range(len(skeletons)):\n",
    "            if skeletons[j][i, 2] < visual_thresh:\n",
    "                continue\n",
    "            if True:\n",
    "                color = colors[i] if color_set is None else colors[\n",
    "                    color_set[j] % len(colors)]\n",
    "            else:\n",
    "                color = get_color(ids[j])\n",
    "\n",
    "            cv2.circle(canvas,\n",
    "                       tuple(skeletons[j][i, 0:2].astype('int32')),\n",
    "                       2,\n",
    "                       color,\n",
    "                       thickness=-1)\n",
    "\n",
    "    for i in range(NUM_EDGES):\n",
    "        for j in range(len(skeletons)):\n",
    "            edge = EDGES[i]\n",
    "            if skeletons[j][edge[0], 2] < visual_thresh or skeletons[j][\n",
    "                    edge[1], 2] < visual_thresh:\n",
    "                continue\n",
    "\n",
    "            cur_canvas = canvas.copy()\n",
    "            X = [skeletons[j][edge[0], 1], skeletons[j][edge[1], 1]]\n",
    "            Y = [skeletons[j][edge[0], 0], skeletons[j][edge[1], 0]]\n",
    "            mX = np.mean(X)\n",
    "            mY = np.mean(Y)\n",
    "            length = ((X[0] - X[1])**2 + (Y[0] - Y[1])**2)**0.5\n",
    "            angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "            polygon = cv2.ellipse2Poly(\n",
    "                (int(mY), int(mX)), (int(length / 2), kp_stick_width), int(angle),\n",
    "                0, 360, 1)\n",
    "            if True:\n",
    "                color = colors[i] if color_set is None else colors[\n",
    "                    color_set[j] % len(colors)]\n",
    "            else:\n",
    "                color = get_color(ids[j])\n",
    "            cv2.fillConvexPoly(cur_canvas, polygon, color)\n",
    "            canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_img = visualize(rgb, kp, params.key_points_visual_thresh, bb_thickness=5, kp_stick_width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
